
import nltk
nltk.download()
import jieba

# from nltk.corpus import brown
# from nltk.stem import SnowballStemmer
#
# print(brown.categories())
# print(len(brown.sents()))

# seg_list = jieba.cut("我是Kevin Shi", cut_all=False)
# print("/ ".join(seg_list))

# snowball_stemmer = SnowballStemmer('english')
# print(snowball_stemmer.stem('中国'))

# sentence = "Python is a widely used high-level programming language for general-purpose programming."
# tokens = nltk.word_tokenize(sentence)
# print(tokens)



